<body>
  <video autoplay></video>
  <span id="left_eye">ðŸ’–</span>
  <span id="right_eye">ðŸ’–</span>
</body>

<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-converter"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/pose-detection"></script>

<script>
  (async () => {
    const video = document.querySelector("video");
    const detector = await poseDetection.createDetector(
      poseDetection.SupportedModels.MoveNet
    );

    const detectEyes = async () => {
      const result = await detector.estimatePoses(video);
      result[0]?.keypoints
        .filter((element) => ["left_eye", "right_eye"].includes(element.name))
        .forEach((element) => {
          const { width, height } = video.getBoundingClientRect()
          document.body.style.setProperty(`--${element.name}_x`, element.x / video.videoWidth * width);
          document.body.style.setProperty(`--${element.name}_y`, element.y / video.videoHeight * height);
        });

      requestAnimationFrame(detectEyes);
    };

    video.addEventListener("loadeddata", detectEyes);

    navigator.getUserMedia(
      { audio: false, video: true },
      (stream) => { video.srcObject = stream; },
      console.error
    );
  })();
</script>

<style>
  body {
    margin: 0;
    --left_eye_x: 0;
    --left_eye_y: 0;
    --right_eye_x: 0;
    --right_eye_y: 0;
  }
  video {
    max-width: 100vw;
  }
  #left_eye, #right_eye {
    position: absolute;
    transform: scale(3);
  }
  #left_eye {
    left: var(--left_eye_x);
    top: var(--left_eye_y);
  }
  #right_eye {
    left: var(--right_eye_x);
    top: var(--right_eye_y);
  }
</style>
